# GLM-4-Voice Real-time Chat

Real-time voice conversation with GLM-4-Voice using streaming audio and server-side VAD.

## Features

- ğŸ¤ Real-time voice chat with instant responses
- ğŸ”Š Streaming audio playback
- ğŸ“ Auto-transcription with OpenAI Whisper
- ğŸ”„ Multi-turn conversations with context
- ğŸ¯ Server-side speech detection (no "send" button)

## Quick Start

### 1. Backend Setup

```bash
cd simple
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure API key
cp env.example .env
# Edit .env: GLM_API_KEY=your_key_here

# Start backend
cd backend
python -m uvicorn main:app --reload --port 8000
```

### 2. Frontend Setup

```bash
# New terminal
cd simple/frontend
npm install
npm run dev
```

### 3. Use the App

1. Open http://localhost:5173
2. Click **Start Chat** and speak
3. Get real-time voice responses
4. Click **End Chat** when done

## Configuration

Edit `backend/config.py` for VAD and audio settings:

```python
# Adjust speech detection sensitivity
SILENCE_THRESHOLD = 0.01
MAX_SILENCE_MS = 700

# Change Whisper model (tiny/base/small/medium/large)
# Trade-off: speed vs accuracy
```

## Project Structure

```
simple/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # WebSocket server
â”‚   â”œâ”€â”€ glm_voice_client.py  # GLM API client
â”‚   â”œâ”€â”€ audio_utils.py       # Audio processing
â”‚   â”œâ”€â”€ vad.py              # Speech detection
â”‚   â””â”€â”€ config.py           # Settings
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.tsx         # Main UI
â”‚       â”œâ”€â”€ audio/          # Recorder & player
â”‚       â””â”€â”€ api/            # WebSocket client
â””â”€â”€ requirements.txt
```

## Troubleshooting

**Microphone not working**
- Use HTTPS or localhost
- Check browser permissions

**High latency**
- Switch to faster Whisper model: `whisper_model_name = "base"` in `config.py`

**Backend errors**
- Check logs for detailed messages
- Verify GLM API key is valid

## Requirements

- Python 3.8+
- Node.js 16+
- GLM API key from [open.bigmodel.cn](https://open.bigmodel.cn/)
